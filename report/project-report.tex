\documentclass[12pt,a4paper]{report}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{url}
\usepackage{listings}
\usepackage{color}
\usepackage{float}
\usepackage{booktabs}
\usepackage{xcolor}

% Code listing settings
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\lstset{style=mystyle}

\usepackage{xcolor}

% Define inline code styling
\lstdefinestyle{inlineCode}{
    backgroundcolor=\color{backcolour},
    basicstyle=\ttfamily\small,
    frame=single,
    breaklines=true,
    columns=flexible
}

% Define custom inline code command
\newcommand{\code}[1]{\lstinline[style=inlineCode]!#1!}


\title{Peer-to-Peer File Sharing System:\\A Robust and Scalable Implementation}
\author{Yugal Khanal\\2302704}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
	The proliferation of distributed systems has led to increased interest in peer-to-peer (P2P) architectures for file sharing. This dissertation presents the design, implementation, and evaluation of a robust P2P file sharing system that addresses key challenges in scalability, fault tolerance, and security. The system implements a hybrid architecture combining centralized tracking with distributed file storage, featuring chunked file transfer, piece verification, and concurrent downloading capabilities.

	The implementation includes sophisticated features such as tracker-based peer discovery, UPnP port mapping for NAT traversal, and a comprehensive piece management system for handling large file transfers. Through extensive testing and evaluation, the system demonstrates reliable performance under various network conditions while maintaining data integrity and transfer efficiency.

	This work contributes to the field by implementing novel approaches to common P2P challenges, including peer availability management and fault-tolerant file transfers, while providing insights into the practical considerations of building distributed systems.

	\textbf{Keywords:} Peer-to-Peer Networks, Distributed Systems, File Sharing, Network Programming, Fault Tolerance
\end{abstract}

\tableofcontents
\listoffigures
\listoftables

\chapter{Introduction}
\section{Background and Motivation}
 [Discussion of the evolution of P2P systems and their role in modern networking]

The increase is the amount of Peer-to-Peer (P2P) file-sharing systems has changed digital content distribution. It's main advantage over it's traditional counterpart client-server model where a central authority manages file transfers is that P2P networks distribute this responsibility over to the peers in the network significantly increasing scalability and fault tolerance.

Data consumption has had a boom in recent years and because of the limitations of the client-server architecture such as high bandwidth costs, central points of failure etc., there has been a demand for efficient, secure and scalable file-sharing mechanisms. Modern P2P networks are the perfect solution to this. They incorporate advanced networking protocols, cryptographic security, and optimisation algorithms to enhance their performance and security. Enhanced scalability is achieved by distributing the file storage and transfer responsibilities among the peers in the network. This reduces the load on individual nodes and improves the overall efficiency of the system. Data redundancy and availability are also improved by storing multiple copies of the file across the network. These two are very strong points for P2P networks and any data distribution system would benefit from these features.

P2P networks have wider applications beyond just simple file-sharing. It's applications range from content distribution networks (CDNs) to blockchains and distributed cloud computing. There are also significant challenges in this approach. Some of them being data security, peer reliability and performance bottlenecks. This project aims to address some of these challenges by designing and implementing a secure, scalable and fault-tolerant P2P file-sharing system.


\section{Project Objectives}
 [Clear enumeration of project goals and success criteria]

The main objective of this project is to design and implement a robust and scalable P2P file-sharing system that addresses key challenges in scalability, fault tolerance, and security. The system will be evaluated based on the following criteria:

\begin{itemize}
	\item Develop a decentralised file-sharing system: The system should be able to handle a large number of peers and files while maintaining performance.
	\item Fault Tolerance: The system should be resilient to peer failures and network disruptions, ensuring reliable file transfers.
	\item Security: The system should implement secure communication protocols and data encryption to protect user data.
	\item Performance: The system should provide efficient file transfer mechanisms and low latency for peer interactions.
	\item Implement secure encryption mechanisms to safeguard data integrity.
\end{itemize}

\section{Evaluation Criteria}
 [Description of the metrics and methods used to evaluate the system]

\begin{itemize}
	\item System Performance: The system's performance will be evaluated it terms of latency, download speeds, system response and throughput efficiency under various network conditions.
	\item Scalability: The system's ability to handle increasing numbers of simultaneous connections and file-sharing requests without performance degradation.
	\item Fault Tolerance: Evaluation of the system's resilience to peer failures and disconnections, network disruptions, and data corruption.
	\item Security: Effefctiveness of the implemented encryption algorithms, peer authentication mechanisms and safeguards against malicious attacks.
	\item Resource Utilization: The system's resource consumption in terms of CPU, memory, and network bandwidth. How efficient the system is in using bandwidth and system resources.
\end{itemize}

By evaluating the system based on these criteria, we can determine the effectiveness of the implemented features and the overall performance of the P2P file-sharing system.
This project will hopefully also contribute to the advancement and highlight the importance of decentralized technologies.

\section{Problem Statement}
 [Detailed description of the challenges in P2P file sharing]

\section{Project Scope}
 [Outline of what the project encompasses and its boundaries]
Peer-to-peer file sharing is the distribuition

\chapter{Literature Review}
\section{History of P2P Systems}
Early peer-to-peer (P2P) file sharing systems showed up in the late 1990s and evolevd rapidly throught the 2000s. Everything started with Napster (1999), created by Shawn Fanning, that allowed users to share music files (MP3) \cite{wikipedia-p2p}. Napster used a centralised server to index available files while the actual file transfers were done directly between user computers (peers). This centralised index made Napster easy to use and very popular. At its peak, Napster had 80 million registered users \cite{wikipedia-napster} which also became its downfall as it was down in 2001 for copyright infringement.

Following Napster, Gnutella was released in 2000 as the very first fully decentralised P2P file sharing network. With Gnutella, the centralised index server was gone; instead, each peer acted equally as a client and a server. The file requests were broadcasted to all peers. At the start, this was great for reliability. However, scaling became a problem as the network grew as flooding each query to all peers caused high overhead and slow searching. Around the same time, other systems like FastTrack (Kazaa, 2001) which became the most popular P2P protocol at the time, used supernodes as indexes to improve scalability. These supernodes were a subset of peers with high-bandwidth that acted as a proxy for other peers \cite{wikipedia-fasttrack}. This combined the central index's efficiency with a decentralised system for actual file transfers. This reduced the overhead of flooding queries to all peers. Similarly, eDonkey2000 (2000) relied on multiple servers for indices, and it's later client eMule (2002) implemented a Kademlia distributed hash table (Kad network) to enable serverless operation.

By the early 2000s,P2P networks had many versions. Some with unstructured networks like Gnutella, structured networks with distributed indices, and hybrid models. The early success and failure of Napster allowed for new P2P file-sharing networks and their software client counterparts \cite{early-2000s-p2p-state}. Since the newer P2P systems don't rely on any central server by using a Distributed Hash Table (DHT), it is much harder for law enforcements to shut it down. The concept of P2P networks has been around for long time. The fundamental Internet Protocols like TCP/IP with its applications in FTP, HTTP, etc. are all based on host-to-host communication where all hosts can request data from all other hosts \cite{early-2000s-p2p-state}. P2P networks are an evolution/extention of these principles, building application-level networks on top of the Internet that directly connect users to each other to freely share any kind of data.

BitTorrent was the biggest milestone in P2P network history, introduced by Bram Cohen in 2001. BitTorrent's totally new and innovative approach to file sharing - discussed in more detail in the next section - immensely improved scalability and efficiency for distributing large files. By utilising swarms of users to concurrently download and upload pieces of a file, BitTorrent was able to reduce the load on individual peers and increase the overall speed of file transfers. This made BitTorrent the most dominant P2P file sharing protocol by the mid-2000s and is still the most popular P2P protocol today \cite{BitTorrent-most-popular}. To summarise, the evolution of P2P file sharing moved from a central index model like Napster, to a purely decentralised but inefficient model like Gnutella, to hybrid and structured network like FastTrack and eDonkey2000, and finally ending up in the efficient and scalable BitTorrent model. These advancements in P2P technology were driven by the need for a lack of central bottlenecks, improved discovery and download speeds and increase reliability (robutness) of the file sharing networks agains failures and legal threats.


\section{BitTorrent Protocol Analysis}
BitTorrent is a peer-to-peer protocol designed for efficient distribution of large files by utilising swarms (the collective group of peers sharing a particular file) to download and upload pieces of the file concurrently. Under the hood, BitTorrent breaks each file into many small pieces called chunks and distributes them among the peers in a swarm, so all participants can download and exchange different pieces with each other simultaneously \cite{bep_0003}. A user requires a torrent descriptor file (.torrent) or a magne link, which contains metadata including a unique info-has identifies for the content and optionally addresses of tracker servers - coordinatin servers that help peers fine each other \cite{bep_0003}. When any BitTorrent client loads this metadata, it joins the swarm by contacting the tracker server or using a Distributed Hash Table (DHT) to discover other peers. Peers in the swarm that have the complete files are called seeders, while those that are still downloading are called leechers or just peers. When the leecher downloads any piece, it begins to upload that piece to others immediately after, contributing to the swarm. This design means that the content distribution load is shared among all peers, and the more peers there are, the faster the download speed can be. With enough peers, a file's original source only needs to provide one full copy, after which the swarm can continue to share the file without the original source's involvement. This decentralised sharing content makes BitTorrent highly scalable.

In a BitTorrent network, at the start, file pieces are downloaded in a strategic order using the \textit{rarest-first}. Peers prioritise requesting pieces that are rarest in the swarm (pieces that fewest other peers have), making those pieces more widely replicated early to ensure availability. This strategy ensures that no single piece/peer becomes a bottleneck in the swarm. BitTorrent also implements a tit-for-tat inspired choking algorithm to encourage cooperation and as it's incentive mechanism. In practice, each client monitors its other peers' upload/download rates and "chokes" (temporarily stops sending data to, downloading can still take place) peers that are not sharing, which unchoking peers that do send data \cite{choking}. Consequently, a peer that uploads more is allowed to download more from others. This leads to faster overall performace for peers that share. This tit-for-tat mechanism is crucial in discouraging free-riders and keeps the swarm healthy. BitTorrent also uses \textit{optimistic unchoking} to randomly unchoke some connections, allowing new and temporarily idle peers to gain pieces \cite{choking}. This also gives a chance to previously choked peers to state that they are willing to share. Because there is no central scheduler, each peer automatically maximises its own download rate by selectively uploading to partners that reciprocate. Doing this also stabilises the download speed, giving peers a consistent download rate.

BitTorrent's swarming approach of downloading pieces from multiple peers in parallel means that the collective bandwidth of the swarm increases as more peers join, greatly improving download efficiency. To put it simply, the swarm's average throughput scales with the number of peers - a sharp contrast and advantage to traditional client-server downloads limited by a server's capacity.

Initially, BitTorrent relied on centralised servers/trackers for peer discovery, but this presented reliability and availability risks (if a tracker went offline, the swarm could become unreachable). To address this, a \textbf{Distributed Hash Table (DHT)} system was introduced (BitTorrent Enhancement Protocol (BEP) 5) to decentralise peer discovery. The DHT is composed of nodes and stores the location of peers. BitTorrent clients include a DHT node, which is used to contact other nodes in the DHT to get the location of peers to download from using the BitTorrent protocol \cite{bep_0005}. The DHT is based on the Kademlia algorithm. In Kademlia, the distance metric is XOR and the result is interpreted as an unsigned integer. distance(A, B) = $|\text{A xor B}|$ smaller values are closer. The distance metric is used to compare two node IDs or a node ID and an infohash for "closeness" \cite{bep_0005}. Peers publish and retrieve torrent swarm information on the DHT by using the torrent's infohash as the key. To find peers for a torrent, a node performs \texttt{get\_peers} query on the DHT with the infohash. The DHT nodes responsible for that key will respond with a list of IP and ports for peers in the swarm. For any peer joining the swarm, the peer uses \texttt{announce\_peer} along with the torrent infohash to announce its presence to the DHT so other nodes can find it \cite{bep_0005}. This way the DHT functions as a decentralised "tracker", allowing peers to find each other without any central server.

In addition to the DHT, BitTorrent also utilises \textbf{Peer Exchange (PEX)} and \textbf{Local Peer Discovery (LDP)} to further improve peer discovery. PEX is an alternative peer discovery mechanish for swarms once peers have bootstrapped via other mechanishms such as DHT \cite{bep_0011}. PEX allows peers to directly exchange peer lists with each other, enabling them to discover new peers quickly without needing a tracker or DHT. LDP allows peers on the same local network (on the same LAN) to discover each other using multicast (http over udp-multicast) \cite{bep_0014}. It's aim is to minimise the traffic through the ISP's channel use the higher LAN bandwidth instead. Together with the DHT, PEX and LDP provide a robust and decentralised peer discovery mechanism for BitTorrent.

Through the combination of efficient piece distribution, tit-for-tat incentive mechanism (choking/unchoking), and multiple peer discovery methods, BitTorrent achieves both very high performance and reliability. BitTorrent remains the most widely used P2P protocol today having inspired many other distributed systems.

\section{Modern P2P Applications}
Although P2P technology began with file sharing, today it is used in a diverse array of modern applications beyond just simple file sharing. One such domain is \textbf{Blockchain} and \textbf{Cryptocurrencies}. They fundamentally operate as P2P networks. In the original white paper for Bitcoin, introduced in 2008, it is described as a "peer-to-peer distributed timestamp server to generate computational proof of the chronological order of transactions" and a Bitcoin to be an electronic coin which is a chain of digital signatures. In a Blockchain network like Bitcoin, each owner transfers the coin to the next by digitally signing a hash of the previous transaction and the public key of the next owner and adding these to the end of the coin without a central authority \cite{bitcoin}. Each node also maintains a copy of the ledger and participates in a proof-of-work protocol to agree on the next block of transactions. The proof-of-work involves finding a value that, when hashed with the block's data, produces a hash with some number of leading zeros \cite{bitcoin}. This decentralised design makes the system resilient and resistant to censorship and attacks. It even has an incentive mechanish to encourage participation in the form of newly minted coins or transaction fees, thereby keeping the network running smoothly. Multiple decentralised applications have been built on blockchain P2P networks (Ethereum being the most popular).

Decentralised data storage and content distribution is another area where P2P networks are used. IPFS (InterPlanetary File System) is a notable example of modern P2P protocol for distributed file storage. It's a protocol and network designed to create a content-addressable, peer-to-peer method of storing and sharing hypermedia in a distributed file system \cite{IPFS}. It forms a global, decentralised file system in which content is addressed by a unique hash. Upon a request for content, the IPFS network uses a DHT to locate peers that have the content and retrieves it from the fastest available sources. This approach allows content to be shared across multiple nodes, making content delivery efficient and reliable (files remain available even if some nodes disconnect, just like in BitTorrent). Many newer applications, especially Web3 applications, leverage IPFS or similar P2P protocols for content distribution without relying on a central server.

From file-sharing to cryptocurrencies and decentralised storage, modern P2P networks demonstrate the versatility and power of decentralised systems. By removing central servers, these applications gain fault-tolerance, increased performance and availability. The principles of P2P networking have been applied to a wide range of applications, and the technology continues to evolve with new use cases and innovations.

\section{Security Challenges in P2P Networks}
Along with the various advantages of P2P networks, they also present significant security and privacy challenges. It's decentralised nature and direct peer-to-peer communication makes enforcing security policies and protecting users more difficult compared to traditional centralisd systems.

\textbf{Privacy and Anonymity} is the primary challenge. In P2P networks, peers' IP addresses are exposed to others in the newtork, meaning user activiy can be monitored. True anonymity is difficult to achieve in P2P networks, as the IP addresses of peers must be published in order to connect and exchange data. This makes it easy for organisations to join swarms to log peer IP addresses and ban those IPs from joining P2P newtorks. Users can use VPNs or other IP masking techniques to hide their true IP address, but this merely shifts the trust to the VPN provider and is not foolproof. As a result, traditional P2P networks offer little built-in anonymity. Some specalised networks emerged to address this issue, like I2P, Freenet, and Tor etc. These networks route traffic through multiple nodes to obfuscate the source and destination of data, providing a higher level of privacy and anonymity. However, they trade off efficiency and are not widely adopted for general file sharing.

\textbf{Malware and Content Integrity} is another major concern. P2P networks are often used to distribute pirated content, which can be a vector for malware. Malicious users can upload malware disguised as legitimate files with no party checking it for authenticity. Users can unknowingly download these files and install malware thinking it is a legitimate file. P2P networks can become a breeding ground for trojans and viruses because of the ease of injection. Attacker can also flood the networks with fake or corrupted files due to the lack of verification \cite{security} \textbf{RECHECK THISSSSSSSSSSSSSSS}.

\chapter{System Architecture}
\section{High-Level Design}

This P2P file sharing system implements a hybrid architecture that combines \textbf{centralised tracking} for peer discovery with \textbf{decentralised file transfer} among peers. This design provides the scalability benefits of distributed systems while maintaining efficient peer discovery through a central coordinator. At a high level, the system consists of the following core components:

\begin{itemize}
	\item \textbf{Tracker Server:} A centralized coordinator that maintains file metadata and peer information, facilitating peer discovery.
	\item \textbf{File Server:} The peer node that handles file sharing, downloading, and storage management.
	\item \textbf{Transport Layer:} Implements both TCP and UDP protocols for reliable file transfer and NAT traversal.
	\item \textbf{Piece Manager:} Manages the downloading of file chunks, implementing strategies for efficient parallel downloads.
	\item \textbf{Storage System:} Handles file chunking, verification, and storage.
\end{itemize}

File transfers are inspired by BitTorrent's approach, where files are divided into chunks, allowing for parallel downloading from multiple peers simultaneously. Each chunk is hashed and verified to maintain data integrity. The combination of all core components ensures a robust and scalable file-sharing experience for users.

\section{Component Overview}
 [Detailed description of system components]
\subsection{Tracker Server}
The Tracker serves as the central coordination point for the P2P networks. This acts as an index for all files available in the network and maintains a list of peers that are actively sharing those files. However, the tracker doesn't participate in the actual file transfer and only helps discover available files along with their respective peers.

\begin{lstlisting}[language=Go, caption=Tracker Implementation]
// Tracker stores metadata and peer information for each file
type Tracker struct {
	fileIndex    map[string]*FileInfo       //file metadata
	peerIndex    map[string]map[string]bool //peer addresses
	peerLastSeen map[string]time.Time       //last heartbeat
	mu           sync.RWMutex
}
\end{lstlisting}

From the tracker implementation, we can see it consists of various important data structures. The \texttt{fileIndex} maps file IDs to \texttt{FileInfo} structure which contains metadata about each file, such as name, size, chunk information, etc. This metadata is necessary for peers to download and reconstruct the file. The \texttt{peerIndex} is a map of file IDs with sets of peer addresses that are sharing that file. This enables the tracker to quickly find peers sharing a particular file and provide their addresses to requesting peers. The \texttt{peerLastSeen} map tracks when each peer was last active in the network, allowing the tracker to clean up inactive peers and maintain an up-to-date list of active peers. The tracker also includes a \texttt{sync.RWMutex} to handle concurrent read and write operations on the data structures.

The Tracker server exposes some useful HTTP endpoints for peers to interact with:
\begin{itemize}
	\item \textbf{/announce:} Allows peers to announce their presence and the files they are sharing.
	\item \textbf{/peers:} Returns a list of peers sharing the requested file.
	\item \textbf{/metadata:} Returns metadata about the requested file.
	\item \textbf{/heartbeat:} Allows peers to signal they are still alive.
	\item \textbf{/remove:} Allows peers to signal they've stopped sharing a file and remove themselves from the network.
\end{itemize}

The Tracker also implements a periodic cleanup mechanism to remove inactive peers from its indices, ensuring that peers attempting to download files are only directed to active and available peers.

\subsection{File Server}
The FileServer component represents a peer node in the P2P network and is responsible for sharing files with other peers and downloading from them. The implementation in \texttt{server.go} shows a complex struct that handles multiple responsibilities.

\begin{lstlisting}[language=Go, caption=File Server Implementation]
type FileServer struct {
	opts             FileServerOpts
	peers            map[string]p2p.Peer
	store            *Store
	quitch           chan struct{}
	mu               sync.RWMutex
	responseHandlers []func(p2p.Message)
	activeFiles      map[string]*shared.Metadata
	activeFilesMu    sync.RWMutex
	udpPeers         map[string]bool
	udpPeersMu       sync.RWMutex
}
\end{lstlisting}



\section{Network Protocol Design}
 [Protocol specifications and communication patterns]

\section{Data Flow Architecture}
 [Data flow diagrams and explanations]

\section{Storage System Design}
 [File storage and management architecture]

\chapter{Implementation Details}
\section{Tracker Implementation}
 [Details of the tracking system]

\section{Peer Discovery and Management}
 [Peer handling mechanisms]

\section{File Chunking and Transfer Protocol}
 [File transfer implementation details]

\section{Concurrent Download Management}
 [Concurrency handling approaches]

\section{Error Handling and Recovery}
 [Error management strategies]

\section{Security Implementation}
 [Security measures and protocols]

\chapter{Technical Challenges and Solutions}
\section{Network NAT Traversal}
 [NAT handling implementation]

\section{File Integrity Verification}
 [Data verification mechanisms]

\section{Peer Availability Management}
 [Peer management strategies]

\section{Performance Optimization}
 [Performance improvements]

\section{Fault Tolerance Implementation}
 [Fault handling approaches]

\chapter{Testing and Evaluation}
\section{Performance Metrics}
 [Performance testing results]

\section{Scalability Testing}
 [Scalability analysis]

\section{Network Resilience}
 [Network testing results]

\section{Security Testing}
 [Security evaluation]

\section{User Experience Testing}
 [Usability assessment]

\chapter{Conclusion and Future Work}
\section{Project Achievements}
 [Summary of accomplishments]

\section{Limitations}
 [Project limitations]

\section{Future Improvements}
 [Potential enhancements]

\section{Final Reflections}
 [Concluding thoughts]

\appendix
\chapter{Code Listings}
\section{Core Components}
% Example code listing:
\begin{lstlisting}[language=Go, caption=Tracker Implementation]
type Tracker struct {
    fileIndex    map[string]*FileInfo
    peerIndex    map[string]map[string]bool
    peerLastSeen map[string]time.Time
    mu           sync.RWMutex
}
\end{lstlisting}

\chapter{Testing Data}
 [Detailed test results and analysis]

\chapter{User Manual}
 [System usage instructions]

\renewcommand\bibname{References}
\begin{raggedright} % Prevents justification issues
	\bibliographystyle{unsrturl}
	\bibliography{references}
\end{raggedright}



\end{document}
